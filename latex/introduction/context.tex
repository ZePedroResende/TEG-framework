In modern science, the need to analyze and process large amounts of data and information has been steadily but surely growing. This need has come to play a significant role to get relevant results from this data-sets.
\par These analyses are mostly done by computer applications that take data-sets and process raw data into useful information with scientific value allowing scientists in all the major fields to achieve discoveries with ease.

\subsection{Intro to HEP-Frame}
 Typically these applications are structured as a sequence of tasks in a pipeline of actions, where data can be modified at each pipeline stage, filtered out and/or output as a result. The next tasks in the pipeline do not process the elements that are filtered out. Actions often vary from intensive computing tasks to simple evaluations that may discard irrelevant data.
\par To aid the development of the software necessary for this kind of problems, a framework was created \textit{\textbf{HEP-Frame}}. This framework allows the user to create a pipeline of tasks and focusing on the result instead of writing the same boilerplate code. To achieve this, most of the duplicated code is generated at compile time through processors, and the repetitive tasks are automated through scripts. Alongside this with the intentions to make these calculations in the shortest time possible and the most efficient way possible. A special scheduler based on graph and list/queue schedulers was developed for this that allows efficient execution under multi-node computer clustering architectures, using parallel computing techniques.
This framework allows for a particular type of process that is incredibly useful for pipeline streaming that if at any stage a validation fails then the data-set is discarded and we can start working on the next set.





\subsection{Contexto scientific data analysis com pipelines que podem ter multiplas saidas que liga com o proximo ponto}
In some cases, an analysis may be carried out where more than one result can be a legitimate outcome for a specific validation. These different constraints can lead to different validations paths and can create possible outcome ramification. This type of task is commonly found in fields of science, such as particle analysis, where we can distinguish different types of particles depending on the values that specific tests obtain.
With the linking of tasks, we create a graph that describes a pipeline with a conditional flow.


\subsection{Definir mais em detalhe o que sao pipelines que podem ter multiplas saidas, que liga com o proximo ponto} 
This type of analysis can be described as a node connected to multiple exit nodes where we have one node for each possible successful outcomes and one to catch a possible fail case.
In each of these nodes, we can expect to have a computation operation and a condition for each possible outcome and respective node.
This can be thought out and modelled as a switch statement where a filter is applied and depending on the result raised by a condition, and a path is chosen for the next node. 

\subsection{Definir Mais em detalhe o que sao pipelines condicionais}
With the pipelines as mentioned earlier, we can describe the concept of conditional pipelines wherein each stage we can have multiple possible steps in which the next task to follow is calculated through a condition.

\subsection{Referir que ainda existe muito pouco trabalho na area de escalonadores para estas pipelines}
Although conditional pipelines have been applied to different domains, at this time, there is little work involved directly to scheduler.